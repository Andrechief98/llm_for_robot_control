# Experimental Results and Metrics

This repository contains the numerical results and analysis scripts for the three different experiments proposed in the article. Each experiment explores distinct aspects of the system under evaluation, and includes relevant data and scripts for metric computation and visualization.

## Repository Structure


## How to use it
### Low Level Control
The python script "low_level_control.py" allows to evaluate the performance of considered LLMs by executing the models generated low level control commands within a Turtlesim simulation using ROS 2. The LLMs responses are stored in the `1.low_level_control/results.json` file.

Before running the script, make sure you have a running instance of the Turtlesim node in ROS 2. You can launch the simulation with the following commands:

```bash
source /opt/ros/humble/setup.bash
ros2 run turtlesim turtlesim_node
```

To check the turtlesim position during the experiment, open a new terminal and launch:
```bash
ros2 topic echo /turtle1/pose
```

Once the simulation is running, the script:

1. Parses the results.json file to extract the command sequences generated by each model.

2. Sends the commands to the Turtlesim node in simulation.

3. Extracts the inference time for each model's output.

4. Computes the mean and standard deviation of the inference times for each model.

### Complex Path Planning
The python script "plot_lemniscate.py" allows to evaluate the performance of considered LLMs in generating complex path (lemniscate) subject to different geometrical contraints. The generated trajectories are stored in the `2.complex_path_planning/results.json` file.

1. When the script is executed, it:

2. Parses the JSON responses to extract the trajectory points for each model.

3. Plots each lemniscate path individually for visual inspection.

4. Extracts the associated inference times from the JSON file.

5. Computes the mean and standard deviation of inference times for each model.

### Obstacle avoidance
This folder contains MATLAB scripts for evaluating the performance of different models in robotic navigation tasks involving both static and dynamic obstacles. The experiments are organized into two main subdirectories:

#### static_obstacles
This folder contains tools for analyzing experiments involving static obstacles:

- plot_metrics_static.m: A MATLAB script that processes ROS bag files from the experiments and computes evaluation metrics for the tested models.

- check_collision.m: A helper function used by the main script to detect collisions between the robot and obstacles.

#### dynamic_obstacles
This folder includes tools for analyzing experiments with dynamic obstacles:

- plot_metrics_dynamic.m: A MATLAB script that processes ROS bag files and computes performance metrics for the tested model.


#### Data Access
Due to the large size of the ROS bag files, they are not included in this repository.
To run the analysis, please download the experiment data from the following link:  [ADD LINK TO THE STORAGE](URL)

After downloading the files, organize the data into the folder structure shown below:

```bash
3.obstacle_avoidance
├── static_obstacles/
|    ├── gpt_4o/
|    ├── gpt_4o few-shot/
|    ├── DeepSeek V3/
|    ├── DeepSeek V3 Few-Shot/
|    ├── o3-mini/
|    ├── check_collision.m
|    └── plot_metrics_static.m
|
|
├── dynamic_obstacles/
    ├── o3-mini/
    └── plot_metrics_dynamic.m
```

## Requirements
- Python script was tested using python 3.10 and ROS2 Humble (Oracle VM VirtualBox with Ubuntu 22.04)
- Matlab scripts were tested with MATLAB2024b


## TODO:
- update the README.file with correct structure of the folders
- bag files stored on the external drive